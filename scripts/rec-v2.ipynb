{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#基础环境配置\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import  preprocessing \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "import operator\n",
    "import math\n",
    "data_dir = '../data'\n",
    "train_data_name = 'train.txt'\n",
    "test_data_name = 'test.txt'\n",
    "train_data_path = os.path.join(data_dir, train_data_name)\n",
    "test_data_path = os.path.join(data_dir, test_data_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#量化评测指标\n",
    "def Recall(train, test, N):\n",
    "    hit = 0\n",
    "    sumd = 0\n",
    "    for user in train.keys():\n",
    "        if user not in test:\n",
    "            continue\n",
    "        tu = test[user]\n",
    "        rank = GetRecommendation(user, N)\n",
    "        for group, pui in rank.items():#pui 评分\n",
    "            if group in tu:\n",
    "                hit += 1\n",
    "        sumd += len(tu)\n",
    "    return float(hit) / sumd\n",
    "\n",
    "def Precision(train, test, N):\n",
    "    hit = 0\n",
    "    sumd = 0\n",
    "    for user in train.keys():\n",
    "        if user not in test:\n",
    "            continue\n",
    "        tu = test[user]\n",
    "        rank = GetRecommendation(user, N)\n",
    "        for gid, pui in rank.items():\n",
    "            if gid in tu:\n",
    "                hit += 1\n",
    "        sumd += N\n",
    "    return float(hit) / sumd\n",
    "\n",
    "def Coverage(train, test, N):\n",
    "    recommend_groups = set()\n",
    "    all_gid = set()\n",
    "    for user in train.keys():\n",
    "        for gid in train[user].keys():\n",
    "            all_gid.add(gid)\n",
    "        rank = GetRecommendation(user, N)\n",
    "        for gid, pui in rank.items():\n",
    "            recommend_groups.add(gid)\n",
    "    return float(len(recommend_groups)) / len(all_gid)\n",
    "\n",
    "def Popularity(train, test, N):\n",
    "    group_popularity = dict()\n",
    "    for user, groups in train.items():\n",
    "        for group in groups.keys():\n",
    "            if group not in group_popularity:\n",
    "                group_popularity[group] = 0\n",
    "            group_popularity[group] += 1\n",
    "    ret = 0\n",
    "    n = 0\n",
    "    for user in train.keys():\n",
    "        rank = GetRecommendation(user, N)\n",
    "        for group, pui in rank.items():\n",
    "            ret += math.log(1 + group_popularity[group])\n",
    "            n += 1\n",
    "    ret /= n * 1.0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#训练集和测试集预处理, 包括\n",
    "# inverse_train\n",
    "# inverse_test\n",
    "# org_fea_mat 原始数据的特征矩阵\n",
    "\n",
    "csv_header = ['uid', 'gid', 'online']\n",
    "df_train = pd.read_csv(train_data_path, names=csv_header)\n",
    "df_test = pd.read_csv(test_data_path, names=csv_header)\n",
    "\n",
    "gidset = set(df_train.gid.unique()) | set(df_test.gid.unique())\n",
    "uidset = set(df_train.uid.unique()) | set(df_test.uid.unique())\n",
    "num_gids = len(gidset)\n",
    "num_uids = len(uidset)\n",
    "inverse_train = defaultdict(defaultdict)\n",
    "inverse_test = defaultdict(defaultdict)\n",
    "org_fea_mat = np.zeros(shape=(num_gids, num_uids))\n",
    "\n",
    "le_gid = preprocessing.LabelEncoder()\n",
    "le_uid = preprocessing.LabelEncoder()\n",
    "le_gid.fit(list(gidset))\n",
    "le_uid.fit(list(uidset))\n",
    "\n",
    "def init_train_data(df):\n",
    "    '''初始化特征矩阵和train'''\n",
    "    gididx = le_gid.transform(df.gid)\n",
    "    uididx = le_uid.transform(df.uid)\n",
    "    org_fea_mat[gididx][uididx] = df.online\n",
    "    inverse_train[uididx][gididx] = df.online\n",
    "    \n",
    "def init_test_data(df):\n",
    "    gididx = le_gid.transform(df.gid)\n",
    "    uididx = le_uid.transform(df.uid)\n",
    "    inverse_test[uididx][gididx] = df.online\n",
    "    \n",
    "tmp1 = df_train.apply(init_train_data, axis=1)\n",
    "tmp2 = df_test.apply(init_test_data, axis=1)\n",
    "\n",
    "normed_fea_mat = preprocessing.normalize(org_fea_mat,norm='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#训练群组相似度矩阵\n",
    "sim_mat = 1-pairwise_distances(org_fea_mat, metric=\"cosine\") #该方法是基于稠密矩阵，对于稀疏矩阵，应该重新实现一个高效的\n",
    "#sim_mat = 1-pairwise_distances(normed_fea_mat, metric=\"euclidean\") #该方法是基于稠密矩阵，对于稀疏矩阵，应该重新实现一个高效的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 411   1 ..., 548 493 221]\n",
      " [  1   3   4 ...,  27  32  14]\n",
      " [  2   4 247 ..., 239   3  14]\n",
      " ..., \n",
      " [740 573 522 ..., 714 351 556]\n",
      " [258 741 738 ..., 607 131 236]\n",
      " [742 362 258 ..., 738 730 386]]\n"
     ]
    }
   ],
   "source": [
    "#用knn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree', metric='pyfunc', func=cosine).fit(normed_fea_mat)\n",
    "W_knn = defaultdict(defaultdict) #基于knn的最近的k个相似度群组\n",
    "distance, indx = nbrs.kneighbors(normed_fea_mat)\n",
    "print indx   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,5,0.0191113490364\n",
      "5,10,0.0132226980728\n",
      "5,15,0.0134368308351\n",
      "5,20,0.01272751606\n",
      "5,40,0.00822403640257\n",
      "10,5,0.0176124197002\n",
      "10,10,0.0130085653105\n",
      "10,15,0.0108137044968\n",
      "10,20,0.00962259100642\n",
      "10,40,0.00696600642398\n",
      "15,5,0.016113490364\n",
      "15,10,0.0121520342612\n",
      "15,15,0.0104568165596\n",
      "15,20,0.00946199143469\n",
      "15,40,0.00689239828694\n",
      "20,5,0.0149892933619\n",
      "20,10,0.0104389721627\n",
      "20,15,0.00901142041399\n",
      "20,20,0.00831102783726\n",
      "20,40,0.00653774089936\n",
      "40,5,0.0107601713062\n",
      "40,10,0.0078426124197\n",
      "40,15,0.00717344753747\n",
      "40,20,0.00645074946467\n",
      "40,40,0.00539346895075\n"
     ]
    }
   ],
   "source": [
    "def RecommendationBasedKnn(train, user_id, distance, indx, K):\n",
    "    rank = defaultdict(lambda: 0)\n",
    "    like_gidset = set(train[user_id].keys())\n",
    "    other_gidset = set(le_gidset - like_gidset)\n",
    "\n",
    "    for i in other_gidset:\n",
    "        for idx, j in enumerate(indx[i]):\n",
    "            if i == j: #在knn的distance列表里，第一个总是他本身\n",
    "                continue\n",
    "            if j not in like_gidset:\n",
    "                continue\n",
    "            online = train[user_id][j]\n",
    "            rank[i] += float(online) * distance[i][idx]\n",
    "        \n",
    "    return dict(sorted(rank.items(), key=operator.itemgetter(1), reverse=True)[0:K])\n",
    "\n",
    "def GetRecommendationBasedKnn(user, N):  \n",
    "    return RecommendationBasedKnn(inverse_train, user, distance,indx, N)\n",
    "\n",
    "def Precision(train, test, N):\n",
    "    hit = 0\n",
    "    sumd = 0\n",
    "    for user in train.keys():\n",
    "        if user not in test:\n",
    "            continue\n",
    "        tu = test[user]\n",
    "        rank = GetRecommendationBasedKnn(user, N)\n",
    "        for gid, pui in rank.items():\n",
    "            if gid in tu:\n",
    "                hit += 1\n",
    "        sumd += N\n",
    "    return float(hit) / sumd\n",
    "\n",
    "for k in [5, 10, 15, 20, 40]:\n",
    "    nbrs = NearestNeighbors(n_neighbors=k,  metric='pyfunc', func=cosine).fit(normed_fea_mat)\n",
    "    W_knn = defaultdict(defaultdict) #基于knn的最近的k个相似度群组\n",
    "    distance, indx = nbrs.kneighbors(normed_fea_mat)\n",
    "    for n in  [5, 10, 15, 20, 40]:\n",
    "        pre =  Precision(inverse_train, inverse_test, n)\n",
    "        print str(k)+','+str(n)+','+str(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.DataFrameGroupBy'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <th>N</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>5</th>\n",
       "      <td>0.013651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>5</th>\n",
       "      <td>0.017345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.007147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">15</th>\n",
       "      <th>5</th>\n",
       "      <td>0.017345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.007133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>5</th>\n",
       "      <td>0.017345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.007147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>5</th>\n",
       "      <td>0.015846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.009904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.006270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              P\n",
       "K  N           \n",
       "5  5   0.013651\n",
       "   10  0.010385\n",
       "   15  0.007887\n",
       "   20  0.006317\n",
       "   40  0.003419\n",
       "10 5   0.017345\n",
       "   10  0.011804\n",
       "   15  0.008833\n",
       "   20  0.007147\n",
       "   40  0.003828\n",
       "15 5   0.017345\n",
       "   10  0.011804\n",
       "   15  0.008833\n",
       "   20  0.007133\n",
       "   40  0.003828\n",
       "20 5   0.017345\n",
       "   10  0.011831\n",
       "   15  0.008851\n",
       "   20  0.007147\n",
       "   40  0.003828\n",
       "40 5   0.015846\n",
       "   10  0.011751\n",
       "   15  0.009904\n",
       "   20  0.008097\n",
       "   40  0.006270"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = pd.read_csv('/Users/yajun/Desktop/test.csv', header=False)\n",
    "preg = df_pre.groupby(['K', 'N'])\n",
    "\n",
    "preg.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin...\n",
      "当N = 5时， Precision = 0.0480064222638, Recall = 0.139242471282, Coverge = 0.74965034965\n",
      "当N = 10时， Precision = 0.0360717152796, Recall = 0.20925178516, Coverge = 0.87972027972\n",
      "当N = 15时， Precision = 0.030505753278, Recall = 0.265445513816, Coverge = 0.914685314685\n",
      "当N = 20时， Precision = 0.0258496119882, Recall = 0.299906861223, Coverge = 0.935664335664\n",
      "end...\n"
     ]
    }
   ],
   "source": [
    "#推荐算法\n",
    "le_gidset = set(range(num_gids)) #得到标签化转化后的gid集合{0，1，2....}\n",
    "N = 8\n",
    "\n",
    "  \n",
    "W = defaultdict(defaultdict)\n",
    "for g, i in enumerate(sim_mat):\n",
    "    for u,j in sorted(enumerate(i), key=operator.itemgetter(1), reverse=True)[1:N+1]:\n",
    "        W[g][u] = sim_mat[g][u]\n",
    "\n",
    "def Recommendation(train, user_id, W, K):\n",
    "    rank = defaultdict(lambda: 0)\n",
    "    like_gidset = set(train[user_id].keys())\n",
    "    other_gidset = set(le_gidset - like_gidset)\n",
    "\n",
    "    for i in other_gidset:\n",
    "        for j, wj in W[i].items():\n",
    "            if j  not in like_gidset:\n",
    "                continue\n",
    "            online = train[user_id][j]\n",
    "            rank[i] += float(online) * wj\n",
    "    return dict(sorted(rank.items(), key=operator.itemgetter(1), reverse=True)[0:K])\n",
    "        \n",
    "def GetRecommendation(user, N):  \n",
    "    return Recommendation(inverse_train, user, W, N)\n",
    "\n",
    "print 'begin...'\n",
    "for i in range(5, 25, 5):\n",
    "    recall = Recall(inverse_train, inverse_test, i)\n",
    "    precision = Precision(inverse_train, inverse_test,i)\n",
    "    coverge = Coverage(inverse_train, inverse_test, i)\n",
    "    #popularity = Popularity(inverse_train, inverse_test, i)\n",
    "    print '当N = ' + str(i) + '时， Precision = ' + str(precision) + ', Recall = ' + str(recall) + ', Coverge = ' + str(coverge) # + ', Popularity= ' + str(popularity)\n",
    "\n",
    "print 'end...'\n",
    "\n",
    "#\n",
    "#实验结果显示，准确率没有采用集合为特征的算法好\n",
    "#可能的原因：\n",
    "#从目前的用户数据看，每个群组内平均下来加入的用户不是很多，因此如果用向量空间模型来表示物品特征，会导致特征矩阵很稀疏"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
